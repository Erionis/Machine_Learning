{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lwvjp5PUb6o"
      },
      "source": [
        "# Classification with Decision Trees and Naive Bayes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tpkP4x7pUkdX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCghdR1LUqSZ"
      },
      "source": [
        "Import and pre-process the data using `pandas`.\n",
        "Data source: https://archive-beta.ics.uci.edu/dataset/73/mushroom\n",
        "\n",
        "For practicality, it also on github (csv format, with features names): https://github.com/GaiaSaveri/intro-to-ml/blob/main/data/Mushroom.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px4uD726Teeg",
        "outputId": "85003909-1365-4194-8a21-b80dc314d51c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Either the file is missing or not readable, download it\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\"wget\" non � riconosciuto come comando interno o esterno,\n",
            " un programma eseguibile o un file batch.\n"
          ]
        }
      ],
      "source": [
        "FFILE = './Mushrooms.csv'\n",
        "if os.path.isfile(FFILE): \n",
        "    print(\"File already exists\")\n",
        "    if os.access(FFILE, os.R_OK):\n",
        "        print (\"File is readable\")\n",
        "    else:\n",
        "        print (\"File is not readable, removing it and downloading again\")\n",
        "        !rm FFILE\n",
        "        !wget \"https://raw.githubusercontent.com/GaiaSaveri/intro-to-ml/main/data/Mushroom.csv\"\n",
        "else:\n",
        "    print(\"Either the file is missing or not readable, download it\")\n",
        "    !wget \"https://raw.githubusercontent.com/GaiaSaveri/intro-to-ml/main/data/Mushroom.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trKzFVZ2aFVp"
      },
      "source": [
        "Divide features and labels and split the dataset into train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "rkF6XEd1aU22",
        "outputId": "02770225-40cb-4a8c-8fea-78d64cb2c5e9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CLASS</th>\n",
              "      <th>CAP-SHAPE</th>\n",
              "      <th>CAP-SURF</th>\n",
              "      <th>CAP-COLOR</th>\n",
              "      <th>BRUISES</th>\n",
              "      <th>ODOR</th>\n",
              "      <th>GILL-ATTACH</th>\n",
              "      <th>GILL-SPACE</th>\n",
              "      <th>GILL-SIZE</th>\n",
              "      <th>GILL-COLOR</th>\n",
              "      <th>...</th>\n",
              "      <th>STALK-SURF-BELOW</th>\n",
              "      <th>STALK-COLOR-ABOVE</th>\n",
              "      <th>STALK-COLOR-BELOW</th>\n",
              "      <th>VEIL-TYPE</th>\n",
              "      <th>VEIL-COLOR</th>\n",
              "      <th>RING-NUM</th>\n",
              "      <th>RING-TYPE</th>\n",
              "      <th>SPORE-PRINT-COLOR</th>\n",
              "      <th>POP</th>\n",
              "      <th>HABIT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EDIBLE</td>\n",
              "      <td>CONVEX</td>\n",
              "      <td>SMOOTH</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>BRUISES</td>\n",
              "      <td>ALMOND</td>\n",
              "      <td>FREE</td>\n",
              "      <td>CROWDED</td>\n",
              "      <td>NARROW</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>...</td>\n",
              "      <td>SMOOTH</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>PARTIAL</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>ONE</td>\n",
              "      <td>PENDANT</td>\n",
              "      <td>PURPLE</td>\n",
              "      <td>SEVERAL</td>\n",
              "      <td>WOODS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EDIBLE</td>\n",
              "      <td>CONVEX</td>\n",
              "      <td>SMOOTH</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>BRUISES</td>\n",
              "      <td>ALMOND</td>\n",
              "      <td>FREE</td>\n",
              "      <td>CROWDED</td>\n",
              "      <td>NARROW</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>...</td>\n",
              "      <td>SMOOTH</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>PARTIAL</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>ONE</td>\n",
              "      <td>PENDANT</td>\n",
              "      <td>BROWN</td>\n",
              "      <td>SEVERAL</td>\n",
              "      <td>WOODS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EDIBLE</td>\n",
              "      <td>CONVEX</td>\n",
              "      <td>SMOOTH</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>BRUISES</td>\n",
              "      <td>ALMOND</td>\n",
              "      <td>FREE</td>\n",
              "      <td>CROWDED</td>\n",
              "      <td>NARROW</td>\n",
              "      <td>PINK</td>\n",
              "      <td>...</td>\n",
              "      <td>SMOOTH</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>PARTIAL</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>ONE</td>\n",
              "      <td>PENDANT</td>\n",
              "      <td>PURPLE</td>\n",
              "      <td>SEVERAL</td>\n",
              "      <td>WOODS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EDIBLE</td>\n",
              "      <td>CONVEX</td>\n",
              "      <td>SMOOTH</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>BRUISES</td>\n",
              "      <td>ALMOND</td>\n",
              "      <td>FREE</td>\n",
              "      <td>CROWDED</td>\n",
              "      <td>NARROW</td>\n",
              "      <td>PINK</td>\n",
              "      <td>...</td>\n",
              "      <td>SMOOTH</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>PARTIAL</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>ONE</td>\n",
              "      <td>PENDANT</td>\n",
              "      <td>BROWN</td>\n",
              "      <td>SEVERAL</td>\n",
              "      <td>WOODS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EDIBLE</td>\n",
              "      <td>CONVEX</td>\n",
              "      <td>SMOOTH</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>BRUISES</td>\n",
              "      <td>ALMOND</td>\n",
              "      <td>FREE</td>\n",
              "      <td>CROWDED</td>\n",
              "      <td>NARROW</td>\n",
              "      <td>BROWN</td>\n",
              "      <td>...</td>\n",
              "      <td>SMOOTH</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>PARTIAL</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>ONE</td>\n",
              "      <td>PENDANT</td>\n",
              "      <td>PURPLE</td>\n",
              "      <td>SEVERAL</td>\n",
              "      <td>WOODS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    CLASS CAP-SHAPE CAP-SURF CAP-COLOR  BRUISES    ODOR GILL-ATTACH  \\\n",
              "0  EDIBLE    CONVEX   SMOOTH     WHITE  BRUISES  ALMOND        FREE   \n",
              "1  EDIBLE    CONVEX   SMOOTH     WHITE  BRUISES  ALMOND        FREE   \n",
              "2  EDIBLE    CONVEX   SMOOTH     WHITE  BRUISES  ALMOND        FREE   \n",
              "3  EDIBLE    CONVEX   SMOOTH     WHITE  BRUISES  ALMOND        FREE   \n",
              "4  EDIBLE    CONVEX   SMOOTH     WHITE  BRUISES  ALMOND        FREE   \n",
              "\n",
              "  GILL-SPACE GILL-SIZE GILL-COLOR  ... STALK-SURF-BELOW STALK-COLOR-ABOVE  \\\n",
              "0    CROWDED    NARROW      WHITE  ...           SMOOTH             WHITE   \n",
              "1    CROWDED    NARROW      WHITE  ...           SMOOTH             WHITE   \n",
              "2    CROWDED    NARROW       PINK  ...           SMOOTH             WHITE   \n",
              "3    CROWDED    NARROW       PINK  ...           SMOOTH             WHITE   \n",
              "4    CROWDED    NARROW      BROWN  ...           SMOOTH             WHITE   \n",
              "\n",
              "  STALK-COLOR-BELOW VEIL-TYPE VEIL-COLOR RING-NUM RING-TYPE SPORE-PRINT-COLOR  \\\n",
              "0             WHITE   PARTIAL      WHITE      ONE   PENDANT            PURPLE   \n",
              "1             WHITE   PARTIAL      WHITE      ONE   PENDANT             BROWN   \n",
              "2             WHITE   PARTIAL      WHITE      ONE   PENDANT            PURPLE   \n",
              "3             WHITE   PARTIAL      WHITE      ONE   PENDANT             BROWN   \n",
              "4             WHITE   PARTIAL      WHITE      ONE   PENDANT            PURPLE   \n",
              "\n",
              "       POP  HABIT  \n",
              "0  SEVERAL  WOODS  \n",
              "1  SEVERAL  WOODS  \n",
              "2  SEVERAL  WOODS  \n",
              "3  SEVERAL  WOODS  \n",
              "4  SEVERAL  WOODS  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_m=pd.read_csv(\"./Mushroom.csv\")\n",
        "train_data_m.head()  # viewing some row of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "0UWaVxlfUQzL",
        "outputId": "cfd86c31-00d4-4ee6-a45d-380f9d7da8f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CLASS</th>\n",
              "      <th>CAP-SHAPE</th>\n",
              "      <th>CAP-SURF</th>\n",
              "      <th>CAP-COLOR</th>\n",
              "      <th>BRUISES</th>\n",
              "      <th>ODOR</th>\n",
              "      <th>GILL-ATTACH</th>\n",
              "      <th>GILL-SPACE</th>\n",
              "      <th>GILL-SIZE</th>\n",
              "      <th>GILL-COLOR</th>\n",
              "      <th>...</th>\n",
              "      <th>STALK-SURF-BELOW</th>\n",
              "      <th>STALK-COLOR-ABOVE</th>\n",
              "      <th>STALK-COLOR-BELOW</th>\n",
              "      <th>VEIL-TYPE</th>\n",
              "      <th>VEIL-COLOR</th>\n",
              "      <th>RING-NUM</th>\n",
              "      <th>RING-TYPE</th>\n",
              "      <th>SPORE-PRINT-COLOR</th>\n",
              "      <th>POP</th>\n",
              "      <th>HABIT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>POISONOUS</td>\n",
              "      <td>CONVEX</td>\n",
              "      <td>SCALY</td>\n",
              "      <td>BROWN</td>\n",
              "      <td>NO</td>\n",
              "      <td>SPICY</td>\n",
              "      <td>FREE</td>\n",
              "      <td>CLOSE</td>\n",
              "      <td>NARROW</td>\n",
              "      <td>BUFF</td>\n",
              "      <td>...</td>\n",
              "      <td>SMOOTH</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>PINK</td>\n",
              "      <td>PARTIAL</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>ONE</td>\n",
              "      <td>EVANESCENT</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>SEVERAL</td>\n",
              "      <td>WOODS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EDIBLE</td>\n",
              "      <td>CONVEX</td>\n",
              "      <td>FIBROUS</td>\n",
              "      <td>RED</td>\n",
              "      <td>BRUISES</td>\n",
              "      <td>NONE</td>\n",
              "      <td>FREE</td>\n",
              "      <td>CLOSE</td>\n",
              "      <td>BROAD</td>\n",
              "      <td>PURPLE</td>\n",
              "      <td>...</td>\n",
              "      <td>SMOOTH</td>\n",
              "      <td>PINK</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>PARTIAL</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>ONE</td>\n",
              "      <td>PENDANT</td>\n",
              "      <td>BROWN</td>\n",
              "      <td>SEVERAL</td>\n",
              "      <td>WOODS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>POISONOUS</td>\n",
              "      <td>FLAT</td>\n",
              "      <td>FIBROUS</td>\n",
              "      <td>GRAY</td>\n",
              "      <td>NO</td>\n",
              "      <td>FOUL</td>\n",
              "      <td>FREE</td>\n",
              "      <td>CLOSE</td>\n",
              "      <td>BROAD</td>\n",
              "      <td>CHOCOLATE</td>\n",
              "      <td>...</td>\n",
              "      <td>SILKY</td>\n",
              "      <td>BUFF</td>\n",
              "      <td>PINK</td>\n",
              "      <td>PARTIAL</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>ONE</td>\n",
              "      <td>LARGE</td>\n",
              "      <td>CHOCOLATE</td>\n",
              "      <td>SOLITARY</td>\n",
              "      <td>GRASSES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EDIBLE</td>\n",
              "      <td>FLAT</td>\n",
              "      <td>FIBROUS</td>\n",
              "      <td>BROWN</td>\n",
              "      <td>NO</td>\n",
              "      <td>NONE</td>\n",
              "      <td>FREE</td>\n",
              "      <td>CROWDED</td>\n",
              "      <td>BROAD</td>\n",
              "      <td>BROWN</td>\n",
              "      <td>...</td>\n",
              "      <td>SMOOTH</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>PARTIAL</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>ONE</td>\n",
              "      <td>EVANESCENT</td>\n",
              "      <td>BROWN</td>\n",
              "      <td>ABUNDANT</td>\n",
              "      <td>GRASSES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EDIBLE</td>\n",
              "      <td>CONVEX</td>\n",
              "      <td>FIBROUS</td>\n",
              "      <td>BROWN</td>\n",
              "      <td>BRUISES</td>\n",
              "      <td>NONE</td>\n",
              "      <td>FREE</td>\n",
              "      <td>CLOSE</td>\n",
              "      <td>BROAD</td>\n",
              "      <td>PURPLE</td>\n",
              "      <td>...</td>\n",
              "      <td>SMOOTH</td>\n",
              "      <td>GRAY</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>PARTIAL</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>ONE</td>\n",
              "      <td>PENDANT</td>\n",
              "      <td>BROWN</td>\n",
              "      <td>SEVERAL</td>\n",
              "      <td>WOODS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       CLASS CAP-SHAPE CAP-SURF CAP-COLOR  BRUISES   ODOR GILL-ATTACH  \\\n",
              "0  POISONOUS    CONVEX    SCALY     BROWN       NO  SPICY        FREE   \n",
              "1     EDIBLE    CONVEX  FIBROUS       RED  BRUISES   NONE        FREE   \n",
              "2  POISONOUS      FLAT  FIBROUS      GRAY       NO   FOUL        FREE   \n",
              "3     EDIBLE      FLAT  FIBROUS     BROWN       NO   NONE        FREE   \n",
              "4     EDIBLE    CONVEX  FIBROUS     BROWN  BRUISES   NONE        FREE   \n",
              "\n",
              "  GILL-SPACE GILL-SIZE GILL-COLOR  ... STALK-SURF-BELOW STALK-COLOR-ABOVE  \\\n",
              "0      CLOSE    NARROW       BUFF  ...           SMOOTH             WHITE   \n",
              "1      CLOSE     BROAD     PURPLE  ...           SMOOTH              PINK   \n",
              "2      CLOSE     BROAD  CHOCOLATE  ...            SILKY              BUFF   \n",
              "3    CROWDED     BROAD      BROWN  ...           SMOOTH             WHITE   \n",
              "4      CLOSE     BROAD     PURPLE  ...           SMOOTH              GRAY   \n",
              "\n",
              "  STALK-COLOR-BELOW VEIL-TYPE VEIL-COLOR RING-NUM   RING-TYPE  \\\n",
              "0              PINK   PARTIAL      WHITE      ONE  EVANESCENT   \n",
              "1             WHITE   PARTIAL      WHITE      ONE     PENDANT   \n",
              "2              PINK   PARTIAL      WHITE      ONE       LARGE   \n",
              "3             WHITE   PARTIAL      WHITE      ONE  EVANESCENT   \n",
              "4             WHITE   PARTIAL      WHITE      ONE     PENDANT   \n",
              "\n",
              "  SPORE-PRINT-COLOR       POP    HABIT  \n",
              "0             WHITE   SEVERAL    WOODS  \n",
              "1             BROWN   SEVERAL    WOODS  \n",
              "2         CHOCOLATE  SOLITARY  GRASSES  \n",
              "3             BROWN  ABUNDANT  GRASSES  \n",
              "4             BROWN   SEVERAL    WOODS  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use first 5000 data points for training and the rest for test\n",
        "train_data_m = train_data_m.sample(frac=1,random_state=0).reset_index(drop=True) # random shufle\n",
        "train_data_m.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OIQJ-4q6Uk-o"
      },
      "outputs": [],
      "source": [
        "train = train_data_m.iloc[:5000,:]\n",
        "test = train_data_m.iloc[5000:,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZOkgoysVJpV"
      },
      "source": [
        "## Decision Trees\n",
        "\n",
        "Make classification with **Decision Trees** using **ID3** (Iterative Dichotomiser 3)\n",
        "\n",
        "Recall: \n",
        "\n",
        "* the decision is built from the dataset and each node is used either to make a decision (internal node) or to represent an outcome (leaves);\n",
        "\n",
        "* ID3 is a top-down (i.e. the tree is constructed starting from the root) greedy (i.e. we consider only the current step in selecting best features) algorithm to build decision trees;\n",
        "\n",
        "* at each step features are divided into two or more groups by computing the **information gain**: the feature with the highest information gain is the best one.\n",
        "\n",
        "  Entropy: $H(S) = \\sum_{i=1}^D -p_i \\log p_i$, $p_i$ proportion of each category\n",
        "\n",
        "  Infromation Gain: $IG(S, j)=H(s) - \\sum_j \\frac{|S_j|}{|S|}H(S_j)$\n",
        "\n",
        "* a node is selected as leaf if all data in the node belong to the same class;\n",
        "\n",
        "* repeat until the tree has all leaf nodes (or features are over).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncpERyjffrwQ"
      },
      "source": [
        "Functions for building the decision tree:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UH7kMkSOZKCp"
      },
      "outputs": [],
      "source": [
        "# compute H(S)\n",
        "def calc_total_entropy(train_data, label, class_list):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_data : matrix n_data x n_features\n",
        "        Matrix containing the training dataset\n",
        "    label : int\n",
        "        Feature used as label\n",
        "    class_list : list of str\n",
        "        Possible values of the label\n",
        "    \"\"\"\n",
        "    total_row = train_data.shape[0]  # the total size of the dataset  \n",
        "    total_entr = 0\n",
        "    for c in class_list:  # for each possible class in the label\n",
        "        total_class_count = train_data[train_data[label] == c].shape[0]  # number of points belonging to the class\n",
        "        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row)  # entropy of the class\n",
        "        total_entr += total_class_entr  # adding the class entropy to the total entropy of the dataset\n",
        "    \n",
        "    return total_entr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Gu--JA60XM03"
      },
      "outputs": [],
      "source": [
        "# compute H(S_j)\n",
        "def calc_entropy(feature_value_data, label, class_list):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    feature_value_data : matrix n_data_selected x n_features\n",
        "        Matrix containing the training points having a certain value of feature j\n",
        "    label : int\n",
        "        Feature used as label\n",
        "    class_list : list of str\n",
        "        Possible values of the label\n",
        "    \"\"\"\n",
        "    class_count = feature_value_data.shape[0] # n points considered\n",
        "    entropy = 0\n",
        "    \n",
        "    for c in class_list:  # for each possible class in the label\n",
        "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0]  # row count of class c \n",
        "        entropy_class = 0\n",
        "        if label_class_count != 0:  # avoid numerical errors\n",
        "            probability_class = label_class_count/class_count  # probability of the class\n",
        "            entropy_class = - probability_class * np.log2(probability_class)  # entropy\n",
        "        entropy += entropy_class\n",
        "    return entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dpXNL4Z-ZHMO"
      },
      "outputs": [],
      "source": [
        "# compute information gain in terms of entropy IG(S, j)\n",
        "def calc_info_gain(feature_name, train_data, label, class_list):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    feature_name : str\n",
        "        Feature considered for computing information gain (j)\n",
        "    train_data : matrix n_data x n_features\n",
        "        Matrix containing the training dataset\n",
        "    label : int\n",
        "        Feature used as label\n",
        "    class_list : list of str\n",
        "        Possible values of the label\n",
        "    \"\"\"\n",
        "    feature_value_list = train_data[feature_name].unique() # unique values of the feature\n",
        "    total_row = train_data.shape[0]\n",
        "    feature_info = 0.0\n",
        "    ##### Check for missing values\n",
        "    a = feature_value_list[feature_value_list=='?']\n",
        "    t = a.shape[0] # number of points with missing value\n",
        "    if (t > 0):  # at least a point is missing the entry for this feature\n",
        "        cmax = 0  # number of points in the most represented class\n",
        "        n = -1\n",
        "        for feature_value in feature_value_list:  # possible values for current feature\n",
        "            n = n + 1\n",
        "            if (feature_value != '?'):        \n",
        "                c = train_data[train_data[feature_name] == feature_value].shape[0]\n",
        "                if (c > cmax):\n",
        "                    cmax = c\n",
        "                    fmax = feature_value # value of the feature with the most points\n",
        "        # replace missing values with the most represented feature value\n",
        "        train_data[feature_name][:]=[fmax if x=='?' else x for x in train_data[feature_name]]\n",
        "    #####  now all the data have a value for the feature under analysis\n",
        "    for feature_value in feature_value_list:\n",
        "        feature_value_data = train_data[train_data[feature_name] == feature_value]  # filtering rows with that feature_value\n",
        "        feature_value_count = feature_value_data.shape[0]  # number of points having feature value in feature j \n",
        "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list) # calculcating entropy for the feature value\n",
        "        feature_value_probability = feature_value_count/total_row\n",
        "        feature_info += feature_value_probability * feature_value_entropy #calculating information of the feature value\n",
        "        \n",
        "    return calc_total_entropy(train_data, label, class_list) - feature_info #calculating information gain by subtracting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6LDMVcNKbjR-"
      },
      "outputs": [],
      "source": [
        "# find feature with maximum information gain\n",
        "def find_most_informative_feature(train_data, label, class_list):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_data : matrix n_data x n_features\n",
        "        Matrix containing the training dataset\n",
        "    label : int\n",
        "        Feature used as label\n",
        "    class_list : list of str\n",
        "        Possible values of the label\n",
        "    \"\"\"\n",
        "    # N.B. label is not a feature, so drop it!\n",
        "    feature_list = train_data.columns.drop(label) #finding the feature names in the dataset                           \n",
        "    max_info_gain = -1\n",
        "    max_info_feature = None\n",
        "    \n",
        "    for feature in feature_list:  # for each feature in the dataset\n",
        "        feature_info_gain = calc_info_gain(feature, train_data, label, class_list)\n",
        "        if max_info_gain < feature_info_gain: # selecting feature name with highest information gain\n",
        "            max_info_gain = feature_info_gain\n",
        "            max_info_feature = feature\n",
        "            \n",
        "    return max_info_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "H0F1Klrnb4xU"
      },
      "outputs": [],
      "source": [
        "# split the tree and check finishing condition \n",
        "def generate_sub_tree(feature_name, train_data, label, class_list):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    feature_name : str\n",
        "        Feature considered at current node\n",
        "    train_data : matrix n_data x n_features\n",
        "        Matrix containing the training dataset\n",
        "    label : int\n",
        "        Feature used as label\n",
        "    class_list : list of str\n",
        "        Possible values of the label\n",
        "    \"\"\"\n",
        "    feature_value_count_dict = train_data[feature_name].value_counts(sort=False)  # dictionary of the count of unqiue feature value\n",
        "    tree = {}  # sub tree or node\n",
        "    \n",
        "    for feature_value, count in feature_value_count_dict.iteritems():\n",
        "        feature_value_data = train_data[train_data[feature_name] == feature_value]  # dataset with only feature_name = feature_value\n",
        "        assigned_to_node = False  # flag for tracking feature_value is pure class or not\n",
        "        for c in class_list:  # for each class\n",
        "            class_count = feature_value_data[feature_value_data[label] == c].shape[0]  # count of class c\n",
        "\n",
        "            if class_count == count:  # count of (feature_value = count) of class (pure class, any value of the feature represents only one class)\n",
        "                tree[feature_value] = c  # adding node to the tree\n",
        "                train_data = train_data[train_data[feature_name] != feature_value]  # removing rows with feature_value\n",
        "                assigned_to_node = True\n",
        "        if not assigned_to_node:  # not pure class\n",
        "            tree[feature_value] = \"?\" # as feature_value is not a pure class, it should be expanded further, \n",
        "                                      # so the branch is marking with ?\n",
        "            \n",
        "    return tree, train_data # in what follows, we have to use this updated dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mSqldicId08d"
      },
      "outputs": [],
      "source": [
        "# generate the tree\n",
        "def make_tree(root, prev_feature_value, train_data, label, class_list):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    root : dict \n",
        "        Tree written as dictionary of subtrees (initially {})\n",
        "    prev_feature_value : str\n",
        "        Previous value of the pointed node (initially None)\n",
        "    train_data : matrix n_data x n_features\n",
        "        Matrix containing the training dataset\n",
        "    label : int\n",
        "        Feature used as label\n",
        "    class_list : list of str\n",
        "        Possible values of the label\n",
        "    \"\"\"\n",
        "    if train_data.shape[0] != 0:  # if dataset becomes empty after updating\n",
        "        max_info_feature = find_most_informative_feature(train_data, label, class_list)  # most informative feature\n",
        "        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list)  # getting tree node and updated dataset\n",
        "        next_root = None\n",
        "        if prev_feature_value != None:  # add to intermediate node of the tree\n",
        "            root[prev_feature_value] = dict()\n",
        "            root[prev_feature_value][max_info_feature] = tree  # expand the tree\n",
        "            next_root = root[prev_feature_value][max_info_feature]\n",
        "        else:  # add to root of the tree\n",
        "            root[max_info_feature] = tree\n",
        "            next_root = root[max_info_feature]\n",
        "        \n",
        "        for node, branch in list(next_root.items()):  # iterating the tree node\n",
        "            if branch == \"?\":  # if it is expandable\n",
        "                feature_value_data = train_data[train_data[max_info_feature] == node]  # using the updated dataset\n",
        "                make_tree(next_root, node, feature_value_data, label, class_list)  # recursive call with updated dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MBvUWsfGfFXI"
      },
      "outputs": [],
      "source": [
        "# id3 call\n",
        "def id3(train_data_m, label):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_data_m : matrix n_data x n_features\n",
        "        Matrix containing the training dataset\n",
        "    label : int\n",
        "        Feature used as label\n",
        "    \"\"\"\n",
        "    train_data = train_data_m.copy()  # getting a copy of the dataset\n",
        "    tree = {}  # tree which will be updated\n",
        "    class_list = train_data[label].unique()  # getting unqiue classes of the label\n",
        "    make_tree(tree, None, train_data, label, class_list)  # start calling recursion\n",
        "    return tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVJS1vcNfkMy"
      },
      "source": [
        "Functions for testing the decision tree algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HaJHf4jkffmN"
      },
      "outputs": [],
      "source": [
        "# prediction from a given instance\n",
        "def predict(tree, instance):\n",
        "  # TODO: missing value o label mancante nel training set \n",
        "    if not isinstance(tree, dict):  # if it is leaf node\n",
        "        return tree  # return the value\n",
        "    else:\n",
        "        root_node = next(iter(tree))  # getting first key/feature name of the dictionary\n",
        "        feature_value = instance[root_node]  # value of the feature\n",
        "        if feature_value in tree[root_node]:  # checking the feature value in current tree node\n",
        "          if (feature_value != \"?\"):  # & (feature_value in tree.keys())):\n",
        "              return predict(tree[root_node][feature_value], instance) # go to next feature\n",
        "        else:\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ExsshgdMffv1"
      },
      "outputs": [],
      "source": [
        "# accuracy evaluation\n",
        "def evaluate(tree, test_data_m, label):\n",
        "    correct_preditct = 0\n",
        "    wrong_preditct = 0\n",
        "    for index in range(len(test_data_m.index)):  # for each row in the dataset\n",
        "        result = predict(tree, test_data_m.iloc[index])  # predict the row\n",
        "        if result == test_data_m[label].iloc[index]:  # predicted value and expected value is same or not\n",
        "            correct_preditct += 1  # increase correct count\n",
        "        else:\n",
        "            wrong_preditct += 1  # increase incorrect count\n",
        "    accuracy = correct_preditct / (correct_preditct + wrong_preditct)  # calculating accuracy\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mo9W9qaZKVH"
      },
      "source": [
        "## Naive Bayes\n",
        "\n",
        "Make classification using the **Naive Bayes** algorithm.\n",
        "\n",
        "Recall: \n",
        "\n",
        "* Bayes Theorem: $p(class|data) \\propto p(data|class)\\cdot p(class)$\n",
        "\n",
        "* prior ($p(class)$) is just the ratio of the number of datapoints belonging to the class;\n",
        "\n",
        "* to make predictions (i.e. compute the posterior $p(class|data)$) we consider the likelihood of each class ($p(data|class)$) computed as a proportion;\n",
        "\n",
        "* we work in the log-space so that predictions will be the class maximizing the sum of prior and likelihood.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Njx_cXjgbom"
      },
      "source": [
        "Function for training the Naive Bayes algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ets-ledrcTIL"
      },
      "outputs": [],
      "source": [
        "def train_naive_bayes(train_data, label):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_data : matrix n_data x n_features\n",
        "        Matrix containing the training dataset\n",
        "    label : int\n",
        "        Feature used as label\n",
        "    \"\"\"\n",
        "    bayes_pi = {}\n",
        "    bayes_tab = {}\n",
        "    ntot = len(train_data.index)\n",
        "    for cl in train_data[label].unique():  # for each possible value of the label\n",
        "        fl = train_data[label]  # select training points in current class\n",
        "        ncl = fl[fl==cl].shape[0]  # count number of points in current class \n",
        "        pcl = ncl/ntot # proportion of points in current class (prior)\n",
        "        bayes_pi[cl] = pcl\n",
        "    for col in train_data.columns: # for each feature\n",
        "        if (col != label):  \n",
        "            dd = pd.crosstab(train_data[label], train_data[col]) # frequency table\n",
        "            a = np.sum(dd)  # total number of points belonging to a class\n",
        "            b = np.sum(a[a.keys()!=\"?\"]) \n",
        "            bayes_tab[col] = dd/b # likelihhod of each class\n",
        "    \n",
        "    return bayes_pi, bayes_tab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtKNvmhBjK5W"
      },
      "source": [
        "Function for testing Naive Bayes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaS8VGpggfaU"
      },
      "outputs": [],
      "source": [
        "# prediction and accuracy evaluation\n",
        "def predict_naive_bayes(test_data, bayes_pi, bayes_tab, label):\n",
        "    ntot = len(test_data.index)\n",
        "    ncorrect = 0\n",
        "    for j in range(ntot):            \n",
        "        prob = bayes_pi.copy()\n",
        "        for col in test_data.columns:\n",
        "            if (col != label):\n",
        "                if ((test_data[col].iloc[j]!=\"?\")&(test_data[col].iloc[j] in bayes_tab[col].keys())):\n",
        "                    for cl in bayes_pi.keys():\n",
        "                        prob[cl] = prob[cl]*bayes_tab[col][test_data[col].iloc[j]][cl]\n",
        "        if (test_data[label].iloc[j] == max(prob, key=prob.get)):\n",
        "            ncorrect = ncorrect + 1\n",
        "    return (ncorrect/ntot) # accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8tLyXsflNoZ"
      },
      "source": [
        "## Results on Mushroom Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiPr8tOYlYEi"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "F4BPTgeXlMxu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ODOR': {'SPICY': 'POISONOUS', 'NONE': {'SPORE-PRINT-COLOR': {'BROWN': 'EDIBLE', 'BLACK': 'EDIBLE', 'WHITE': {'HABIT': {'GRASSES': 'EDIBLE', 'WASTE': 'EDIBLE', 'LEAVES': {'CAP-COLOR': {'BROWN': 'EDIBLE', 'CINNAMON': 'EDIBLE', 'YELLOW': 'POISONOUS', 'WHITE': 'POISONOUS'}}, 'WOODS': {'GILL-SIZE': {'BROAD': 'EDIBLE', 'NARROW': 'POISONOUS'}}, 'PATHS': 'EDIBLE'}}, 'ORANGE': 'EDIBLE', 'BUFF': 'EDIBLE', 'YELLOW': 'EDIBLE', 'GREEN': 'POISONOUS', 'CHOCOLATE': 'EDIBLE'}}, 'FOUL': 'POISONOUS', 'PUNGENT': 'POISONOUS', 'FISHY': 'POISONOUS', 'ANISE': 'EDIBLE', 'CREOSOTE': 'POISONOUS', 'ALMOND': 'EDIBLE', 'MUSTY': 'POISONOUS'}}\n"
          ]
        }
      ],
      "source": [
        "tree = id3(train, \"CLASS\")\n",
        "print(tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vpu1eag3loSF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n"
          ]
        }
      ],
      "source": [
        "accuracy = evaluate(tree, test, \"CLASS\")\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYZm1lw4la5D"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PxbQUc7KlnIn"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_naive_bayes' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Erion\\Desktop\\Machine Learning\\ML-GIT\\Machine_Learning\\notebooks\\06_DecisionTreeNaiveBayes.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Erion/Desktop/Machine%20Learning/ML-GIT/Machine_Learning/notebooks/06_DecisionTreeNaiveBayes.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pi, tab \u001b[39m=\u001b[39m train_naive_bayes(train, \u001b[39m\"\u001b[39m\u001b[39mCLASS\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'train_naive_bayes' is not defined"
          ]
        }
      ],
      "source": [
        "pi, tab = train_naive_bayes(train, \"CLASS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gsm-i5VdmYBE"
      },
      "outputs": [],
      "source": [
        "accuracy = predict_naive_bayes(test, pi, tab,\"CLASS\")\n",
        "print(accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
