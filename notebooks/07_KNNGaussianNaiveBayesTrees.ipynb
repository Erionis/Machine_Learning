{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo66foonmvxg"
      },
      "source": [
        "# Classification with KNN, Trees and Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v3kH50wbmjBL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_cnE38km64G"
      },
      "source": [
        "Load and split the data from the Unsupervise Learning Dataset (Lab 5, Dry Bean Dataset):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g0eM9w9HnRDf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists\n",
            "File is readable\n"
          ]
        }
      ],
      "source": [
        "FFILE = './Dry_Bean_Dataset.xlsx'\n",
        "if os.path.isfile(FFILE): \n",
        "    print(\"File already exists\")\n",
        "    if os.access(FFILE, os.R_OK):\n",
        "        print (\"File is readable\")\n",
        "    else:\n",
        "        print (\"File is not readable, removing it and downloading again\")\n",
        "        !rm FFILE\n",
        "        !wget \"https://raw.github.com/alexdepremia/ML_IADA_UTs/main/Lab5/Dry_Bean_Dataset.xlsx\"\n",
        "else:\n",
        "    print(\"Either the file is missing or not readable, download it\")\n",
        "    !wget \"https://raw.github.com/alexdepremia/ML_IADA_UTs/main/Lab5/Dry_Bean_Dataset.xlsx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CPt8p6GsnTGQ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Perimeter</th>\n",
              "      <th>MajorAxisLength</th>\n",
              "      <th>MinorAxisLength</th>\n",
              "      <th>AspectRation</th>\n",
              "      <th>Eccentricity</th>\n",
              "      <th>ConvexArea</th>\n",
              "      <th>EquivDiameter</th>\n",
              "      <th>Extent</th>\n",
              "      <th>Solidity</th>\n",
              "      <th>roundness</th>\n",
              "      <th>Compactness</th>\n",
              "      <th>ShapeFactor1</th>\n",
              "      <th>ShapeFactor2</th>\n",
              "      <th>ShapeFactor3</th>\n",
              "      <th>ShapeFactor4</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28395</td>\n",
              "      <td>610.291</td>\n",
              "      <td>208.178117</td>\n",
              "      <td>173.888747</td>\n",
              "      <td>1.197191</td>\n",
              "      <td>0.549812</td>\n",
              "      <td>28715</td>\n",
              "      <td>190.141097</td>\n",
              "      <td>0.763923</td>\n",
              "      <td>0.988856</td>\n",
              "      <td>0.958027</td>\n",
              "      <td>0.913358</td>\n",
              "      <td>0.007332</td>\n",
              "      <td>0.003147</td>\n",
              "      <td>0.834222</td>\n",
              "      <td>0.998724</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28734</td>\n",
              "      <td>638.018</td>\n",
              "      <td>200.524796</td>\n",
              "      <td>182.734419</td>\n",
              "      <td>1.097356</td>\n",
              "      <td>0.411785</td>\n",
              "      <td>29172</td>\n",
              "      <td>191.272750</td>\n",
              "      <td>0.783968</td>\n",
              "      <td>0.984986</td>\n",
              "      <td>0.887034</td>\n",
              "      <td>0.953861</td>\n",
              "      <td>0.006979</td>\n",
              "      <td>0.003564</td>\n",
              "      <td>0.909851</td>\n",
              "      <td>0.998430</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29380</td>\n",
              "      <td>624.110</td>\n",
              "      <td>212.826130</td>\n",
              "      <td>175.931143</td>\n",
              "      <td>1.209713</td>\n",
              "      <td>0.562727</td>\n",
              "      <td>29690</td>\n",
              "      <td>193.410904</td>\n",
              "      <td>0.778113</td>\n",
              "      <td>0.989559</td>\n",
              "      <td>0.947849</td>\n",
              "      <td>0.908774</td>\n",
              "      <td>0.007244</td>\n",
              "      <td>0.003048</td>\n",
              "      <td>0.825871</td>\n",
              "      <td>0.999066</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30008</td>\n",
              "      <td>645.884</td>\n",
              "      <td>210.557999</td>\n",
              "      <td>182.516516</td>\n",
              "      <td>1.153638</td>\n",
              "      <td>0.498616</td>\n",
              "      <td>30724</td>\n",
              "      <td>195.467062</td>\n",
              "      <td>0.782681</td>\n",
              "      <td>0.976696</td>\n",
              "      <td>0.903936</td>\n",
              "      <td>0.928329</td>\n",
              "      <td>0.007017</td>\n",
              "      <td>0.003215</td>\n",
              "      <td>0.861794</td>\n",
              "      <td>0.994199</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30140</td>\n",
              "      <td>620.134</td>\n",
              "      <td>201.847882</td>\n",
              "      <td>190.279279</td>\n",
              "      <td>1.060798</td>\n",
              "      <td>0.333680</td>\n",
              "      <td>30417</td>\n",
              "      <td>195.896503</td>\n",
              "      <td>0.773098</td>\n",
              "      <td>0.990893</td>\n",
              "      <td>0.984877</td>\n",
              "      <td>0.970516</td>\n",
              "      <td>0.006697</td>\n",
              "      <td>0.003665</td>\n",
              "      <td>0.941900</td>\n",
              "      <td>0.999166</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
              "0  28395    610.291       208.178117       173.888747      1.197191   \n",
              "1  28734    638.018       200.524796       182.734419      1.097356   \n",
              "2  29380    624.110       212.826130       175.931143      1.209713   \n",
              "3  30008    645.884       210.557999       182.516516      1.153638   \n",
              "4  30140    620.134       201.847882       190.279279      1.060798   \n",
              "\n",
              "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
              "0      0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
              "1      0.411785       29172     191.272750  0.783968  0.984986   0.887034   \n",
              "2      0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
              "3      0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
              "4      0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
              "\n",
              "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  Class  \n",
              "0     0.913358      0.007332      0.003147      0.834222      0.998724  SEKER  \n",
              "1     0.953861      0.006979      0.003564      0.909851      0.998430  SEKER  \n",
              "2     0.908774      0.007244      0.003048      0.825871      0.999066  SEKER  \n",
              "3     0.928329      0.007017      0.003215      0.861794      0.994199  SEKER  \n",
              "4     0.970516      0.006697      0.003665      0.941900      0.999166  SEKER  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the data\n",
        "data = pd.read_excel('./Dry_Bean_Dataset.xlsx')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5m3HOy0nny0"
      },
      "source": [
        "Divide features and label. Split the data in train and test set and **after that** normalize them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZpAplcpvnunq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Perimeter</th>\n",
              "      <th>MajorAxisLength</th>\n",
              "      <th>MinorAxisLength</th>\n",
              "      <th>AspectRation</th>\n",
              "      <th>Eccentricity</th>\n",
              "      <th>ConvexArea</th>\n",
              "      <th>EquivDiameter</th>\n",
              "      <th>Extent</th>\n",
              "      <th>Solidity</th>\n",
              "      <th>roundness</th>\n",
              "      <th>Compactness</th>\n",
              "      <th>ShapeFactor1</th>\n",
              "      <th>ShapeFactor2</th>\n",
              "      <th>ShapeFactor3</th>\n",
              "      <th>ShapeFactor4</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37277</td>\n",
              "      <td>710.193</td>\n",
              "      <td>264.789840</td>\n",
              "      <td>179.808422</td>\n",
              "      <td>1.472622</td>\n",
              "      <td>0.734082</td>\n",
              "      <td>37684</td>\n",
              "      <td>217.859015</td>\n",
              "      <td>0.802692</td>\n",
              "      <td>0.989200</td>\n",
              "      <td>0.928748</td>\n",
              "      <td>0.822762</td>\n",
              "      <td>0.007103</td>\n",
              "      <td>0.002008</td>\n",
              "      <td>0.676937</td>\n",
              "      <td>0.996873</td>\n",
              "      <td>DERMASON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28942</td>\n",
              "      <td>638.821</td>\n",
              "      <td>239.861192</td>\n",
              "      <td>154.004371</td>\n",
              "      <td>1.557496</td>\n",
              "      <td>0.766658</td>\n",
              "      <td>29368</td>\n",
              "      <td>191.963796</td>\n",
              "      <td>0.786126</td>\n",
              "      <td>0.985494</td>\n",
              "      <td>0.891210</td>\n",
              "      <td>0.800312</td>\n",
              "      <td>0.008288</td>\n",
              "      <td>0.002097</td>\n",
              "      <td>0.640499</td>\n",
              "      <td>0.997575</td>\n",
              "      <td>DERMASON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38290</td>\n",
              "      <td>719.888</td>\n",
              "      <td>270.446510</td>\n",
              "      <td>180.508066</td>\n",
              "      <td>1.498252</td>\n",
              "      <td>0.744659</td>\n",
              "      <td>38605</td>\n",
              "      <td>220.799326</td>\n",
              "      <td>0.759903</td>\n",
              "      <td>0.991840</td>\n",
              "      <td>0.928465</td>\n",
              "      <td>0.816425</td>\n",
              "      <td>0.007063</td>\n",
              "      <td>0.001936</td>\n",
              "      <td>0.666550</td>\n",
              "      <td>0.998660</td>\n",
              "      <td>DERMASON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37641</td>\n",
              "      <td>742.538</td>\n",
              "      <td>284.313737</td>\n",
              "      <td>169.740814</td>\n",
              "      <td>1.674987</td>\n",
              "      <td>0.802227</td>\n",
              "      <td>38112</td>\n",
              "      <td>218.920099</td>\n",
              "      <td>0.744187</td>\n",
              "      <td>0.987642</td>\n",
              "      <td>0.857894</td>\n",
              "      <td>0.769995</td>\n",
              "      <td>0.007553</td>\n",
              "      <td>0.001638</td>\n",
              "      <td>0.592892</td>\n",
              "      <td>0.993087</td>\n",
              "      <td>SIRA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50172</td>\n",
              "      <td>828.968</td>\n",
              "      <td>316.453571</td>\n",
              "      <td>202.268818</td>\n",
              "      <td>1.564520</td>\n",
              "      <td>0.769062</td>\n",
              "      <td>50547</td>\n",
              "      <td>252.746858</td>\n",
              "      <td>0.688240</td>\n",
              "      <td>0.992581</td>\n",
              "      <td>0.917478</td>\n",
              "      <td>0.798685</td>\n",
              "      <td>0.006307</td>\n",
              "      <td>0.001583</td>\n",
              "      <td>0.637898</td>\n",
              "      <td>0.998005</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
              "0  37277    710.193       264.789840       179.808422      1.472622   \n",
              "1  28942    638.821       239.861192       154.004371      1.557496   \n",
              "2  38290    719.888       270.446510       180.508066      1.498252   \n",
              "3  37641    742.538       284.313737       169.740814      1.674987   \n",
              "4  50172    828.968       316.453571       202.268818      1.564520   \n",
              "\n",
              "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
              "0      0.734082       37684     217.859015  0.802692  0.989200   0.928748   \n",
              "1      0.766658       29368     191.963796  0.786126  0.985494   0.891210   \n",
              "2      0.744659       38605     220.799326  0.759903  0.991840   0.928465   \n",
              "3      0.802227       38112     218.920099  0.744187  0.987642   0.857894   \n",
              "4      0.769062       50547     252.746858  0.688240  0.992581   0.917478   \n",
              "\n",
              "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n",
              "0     0.822762      0.007103      0.002008      0.676937      0.996873   \n",
              "1     0.800312      0.008288      0.002097      0.640499      0.997575   \n",
              "2     0.816425      0.007063      0.001936      0.666550      0.998660   \n",
              "3     0.769995      0.007553      0.001638      0.592892      0.993087   \n",
              "4     0.798685      0.006307      0.001583      0.637898      0.998005   \n",
              "\n",
              "      Class  \n",
              "0  DERMASON  \n",
              "1  DERMASON  \n",
              "2  DERMASON  \n",
              "3      SIRA  \n",
              "4     SEKER  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data.sample(frac=1,random_state=0).reset_index(drop=True) # random shuffle\n",
        "data.head()   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K9I8tR3gZanQ"
      },
      "outputs": [],
      "source": [
        "train_data = data.iloc[:10000,:]\n",
        "test_data = data.iloc[10000:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "w4Sai6BSZkWf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 17)\n",
            "(3611, 17)\n"
          ]
        }
      ],
      "source": [
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tIl6l3KXZsO3"
      },
      "outputs": [],
      "source": [
        "# normalize train and test dataset \n",
        "from sklearn import preprocessing\n",
        "\n",
        "label_train = train_data['Class']\n",
        "train_data = train_data.drop('Class', axis=1)\n",
        "\n",
        "columns_name = train_data.columns\n",
        "train_scaler = preprocessing.StandardScaler().fit(train_data)\n",
        "train_data = train_scaler.transform(train_data)\n",
        "train_data = pd.DataFrame(train_data, columns=columns_name)\n",
        "train_data['Class'] = label_train\n",
        "label_test = test_data['Class']\n",
        "test_data = test_data.drop('Class', axis=1)\n",
        "test_scaler = preprocessing.StandardScaler().fit(test_data)\n",
        "test_data = test_scaler.transform(test_data)\n",
        "test_data = pd.DataFrame(test_data, columns=columns_name)\n",
        "test_data['Class'] = label_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WdaI84S-eDNZ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Perimeter</th>\n",
              "      <th>MajorAxisLength</th>\n",
              "      <th>MinorAxisLength</th>\n",
              "      <th>AspectRation</th>\n",
              "      <th>Eccentricity</th>\n",
              "      <th>ConvexArea</th>\n",
              "      <th>EquivDiameter</th>\n",
              "      <th>Extent</th>\n",
              "      <th>Solidity</th>\n",
              "      <th>roundness</th>\n",
              "      <th>Compactness</th>\n",
              "      <th>ShapeFactor1</th>\n",
              "      <th>ShapeFactor2</th>\n",
              "      <th>ShapeFactor3</th>\n",
              "      <th>ShapeFactor4</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.534137</td>\n",
              "      <td>-0.673988</td>\n",
              "      <td>-0.642784</td>\n",
              "      <td>-0.494897</td>\n",
              "      <td>-0.448854</td>\n",
              "      <td>-0.185185</td>\n",
              "      <td>-0.536571</td>\n",
              "      <td>-0.590932</td>\n",
              "      <td>1.083156</td>\n",
              "      <td>0.441530</td>\n",
              "      <td>0.932328</td>\n",
              "      <td>0.372606</td>\n",
              "      <td>0.473404</td>\n",
              "      <td>0.490160</td>\n",
              "      <td>0.338721</td>\n",
              "      <td>0.416048</td>\n",
              "      <td>DERMASON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.819126</td>\n",
              "      <td>-1.008115</td>\n",
              "      <td>-0.934618</td>\n",
              "      <td>-1.070089</td>\n",
              "      <td>-0.104138</td>\n",
              "      <td>0.170622</td>\n",
              "      <td>-0.816632</td>\n",
              "      <td>-1.029793</td>\n",
              "      <td>0.746572</td>\n",
              "      <td>-0.348554</td>\n",
              "      <td>0.302277</td>\n",
              "      <td>0.007584</td>\n",
              "      <td>1.526541</td>\n",
              "      <td>0.640814</td>\n",
              "      <td>-0.030790</td>\n",
              "      <td>0.576165</td>\n",
              "      <td>DERMASON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.499500</td>\n",
              "      <td>-0.628601</td>\n",
              "      <td>-0.576563</td>\n",
              "      <td>-0.479301</td>\n",
              "      <td>-0.344759</td>\n",
              "      <td>-0.069652</td>\n",
              "      <td>-0.505554</td>\n",
              "      <td>-0.541101</td>\n",
              "      <td>0.213791</td>\n",
              "      <td>1.004632</td>\n",
              "      <td>0.927566</td>\n",
              "      <td>0.269572</td>\n",
              "      <td>0.437664</td>\n",
              "      <td>0.368508</td>\n",
              "      <td>0.233385</td>\n",
              "      <td>0.823378</td>\n",
              "      <td>DERMASON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.521691</td>\n",
              "      <td>-0.522565</td>\n",
              "      <td>-0.414222</td>\n",
              "      <td>-0.719312</td>\n",
              "      <td>0.373055</td>\n",
              "      <td>0.559127</td>\n",
              "      <td>-0.522157</td>\n",
              "      <td>-0.572949</td>\n",
              "      <td>-0.105517</td>\n",
              "      <td>0.109317</td>\n",
              "      <td>-0.256904</td>\n",
              "      <td>-0.485355</td>\n",
              "      <td>0.873546</td>\n",
              "      <td>-0.133675</td>\n",
              "      <td>-0.513569</td>\n",
              "      <td>-0.447017</td>\n",
              "      <td>SIRA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.093232</td>\n",
              "      <td>-0.117944</td>\n",
              "      <td>-0.037969</td>\n",
              "      <td>0.005762</td>\n",
              "      <td>-0.075610</td>\n",
              "      <td>0.196889</td>\n",
              "      <td>-0.103380</td>\n",
              "      <td>0.000331</td>\n",
              "      <td>-1.242245</td>\n",
              "      <td>1.162580</td>\n",
              "      <td>0.743167</td>\n",
              "      <td>-0.018863</td>\n",
              "      <td>-0.234347</td>\n",
              "      <td>-0.225790</td>\n",
              "      <td>-0.057166</td>\n",
              "      <td>0.674089</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
              "0 -0.534137  -0.673988        -0.642784        -0.494897     -0.448854   \n",
              "1 -0.819126  -1.008115        -0.934618        -1.070089     -0.104138   \n",
              "2 -0.499500  -0.628601        -0.576563        -0.479301     -0.344759   \n",
              "3 -0.521691  -0.522565        -0.414222        -0.719312      0.373055   \n",
              "4 -0.093232  -0.117944        -0.037969         0.005762     -0.075610   \n",
              "\n",
              "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
              "0     -0.185185   -0.536571      -0.590932  1.083156  0.441530   0.932328   \n",
              "1      0.170622   -0.816632      -1.029793  0.746572 -0.348554   0.302277   \n",
              "2     -0.069652   -0.505554      -0.541101  0.213791  1.004632   0.927566   \n",
              "3      0.559127   -0.522157      -0.572949 -0.105517  0.109317  -0.256904   \n",
              "4      0.196889   -0.103380       0.000331 -1.242245  1.162580   0.743167   \n",
              "\n",
              "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n",
              "0     0.372606      0.473404      0.490160      0.338721      0.416048   \n",
              "1     0.007584      1.526541      0.640814     -0.030790      0.576165   \n",
              "2     0.269572      0.437664      0.368508      0.233385      0.823378   \n",
              "3    -0.485355      0.873546     -0.133675     -0.513569     -0.447017   \n",
              "4    -0.018863     -0.234347     -0.225790     -0.057166      0.674089   \n",
              "\n",
              "      Class  \n",
              "0  DERMASON  \n",
              "1  DERMASON  \n",
              "2  DERMASON  \n",
              "3      SIRA  \n",
              "4     SEKER  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxDH5MYE21sj"
      },
      "source": [
        "**Before feeding the data into the following algorithms, try to perform PCA, varying the number of PCs, and check what changes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FptPlXMAnuym"
      },
      "source": [
        "## K-Nearest Neighbors Classification \n",
        "\n",
        "Implement the KNN algorithm for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "urjD3tGR3DV7"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "def distance(point_one, point_two):\n",
        "    return euclidean(point_one, point_two)\n",
        "\n",
        "def get_neighbors(train_set, test_point, label_col, n_neighbors):\n",
        "  dist = np.array([distance(train_point, test_point) for train_point in train_set])\n",
        "  idx_dist = dist.argsort()\n",
        "  ordered_train = train_set[idx_dist, :]\n",
        "  ordered_label = label_col[idx_dist]\n",
        "  return ordered_train[:n_neighbors], ordered_label[:n_neighbors]\n",
        "\n",
        "def predict(train_set, test_point, labels, n_neighbors):\n",
        "  neigh, neigh_label = get_neighbors(train_set, test_point, labels, n_neighbors)\n",
        "  values, counts = np.unique(neigh_label, return_counts=True)\n",
        "  idx = np.argmax(counts)\n",
        "  return values[idx]\n",
        "\n",
        "def evaluate(train_set, test_set, label, n_neighbors=2):\n",
        "    correct_preditct = 0\n",
        "    wrong_preditct = 0\n",
        "    train_labels = train_set[label].values\n",
        "    train_set = train_set.drop(label, axis=1)\n",
        "    test_labels = test_set[label].values\n",
        "    test_set = test_set.drop(label, axis=1)\n",
        "    for index in range(len(test_set.index)):  # for each row in the dataset\n",
        "        result = predict(train_set.values, test_set.iloc[index].values, train_labels, n_neighbors)  # predict the row\n",
        "        if result == test_labels[index]:  # predicted value and expected value is same or not\n",
        "            correct_preditct += 1  # increase correct count\n",
        "        else:\n",
        "            wrong_preditct += 1  # increase incorrect count\n",
        "    accuracy = correct_preditct / (correct_preditct + wrong_preditct)  # calculating accuracy\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cOUsnIsElYNA"
      },
      "outputs": [],
      "source": [
        "knn_accuracy = evaluate(train_data, test_data, 'Class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZd_CqNr3DnI"
      },
      "source": [
        "## Decision Trees with Numerical Features \n",
        "\n",
        "Modify the implementation of decision trees to account for numerical input features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yVWtuSI3Q07"
      },
      "outputs": [],
      "source": [
        "# compute H(S)\n",
        "def entropy(train_data, label, class_list):\n",
        "    total_row = train_data.shape[0]  # the total size of the dataset  \n",
        "    total_entr = 0\n",
        "    for c in class_list:  # for each possible class in the label\n",
        "        total_class_count = train_data[train_data[label] == c].shape[0]  # number of points belonging to the class\n",
        "        if total_class_count > 0:\n",
        "          total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row)  # entropy of the class\n",
        "          total_entr += total_class_entr  # adding the class entropy to the total entropy of the dataset\n",
        "    return total_entr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAF8R0lT03Um"
      },
      "outputs": [],
      "source": [
        "# compute H(S_j)\n",
        "def feature_entropy(left_data, right_data, label, class_list):\n",
        "    row_count = left_data.shape[0] + right_data.shape[0] # n points considered\n",
        "    p_left = left_data.shape[0] / row_count\n",
        "    p_right = right_data.shape[0] / row_count\n",
        "    ent = p_left * entropy(left_data, label, class_list) + p_right * entropy(right_data, label, class_list)\n",
        "    return ent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caDIpINC86M3"
      },
      "outputs": [],
      "source": [
        "def split(feature_column, threshold):\n",
        "  left_rows = np.argwhere(feature_column <= threshold).flatten()\n",
        "  right_rows = np.argwhere(feature_column > threshold).flatten()\n",
        "  return left_rows, right_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M73J3Pq39UxT"
      },
      "outputs": [],
      "source": [
        "def information_gain(data, feature_name, label, class_list, threshold):\n",
        "  left_rows, right_rows = split(data[feature_name].values, threshold)\n",
        "  if len(left_rows)==0 or len(right_rows)==0:\n",
        "    return 0\n",
        "  feat_entropy = feature_entropy(data.iloc[left_rows], data.iloc[right_rows], label, class_list)\n",
        "  return feat_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceevhRt4M8a3"
      },
      "outputs": [],
      "source": [
        "def get_split_thresholds(feature_column, n_thresholds):\n",
        "  feature_column = feature_column.values\n",
        "  n_data = len(feature_column)\n",
        "  sorted_column = np.sort(feature_column)\n",
        "  if len(feature_column) > 1:\n",
        "    partitioned_array = np.array_split(feature_column, n_thresholds + 1)\n",
        "    thresholds = [(partitioned_array[i][-1] + partitioned_array[i+1][0])/2 for i in range(len(partitioned_array)-1)]\n",
        "  else:\n",
        "    thresholds = [feature_column[0]]\n",
        "  return thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0_szcme8WPS"
      },
      "outputs": [],
      "source": [
        "def most_informative_feature(train_data, label, class_list, n_thresholds):\n",
        "    feature_list = train_data.columns.drop(label)\n",
        "    min_entropy = 99999\n",
        "    min_entropy_feature = None\n",
        "    min_entropy_threshold = None\n",
        "    for feature in feature_list:\n",
        "      thresholds = get_split_thresholds(train_data[feature], n_thresholds)\n",
        "      for t in thresholds:\n",
        "        info_gain = information_gain(train_data, feature, label, class_list, t)\n",
        "        if info_gain < min_entropy:\n",
        "          min_entropy = info_gain\n",
        "          min_entropy_feature = feature\n",
        "          min_entropy_threshold = t\n",
        "    return min_entropy_feature, min_entropy_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFkkyLqj67Ce"
      },
      "outputs": [],
      "source": [
        "def is_leaf(train_data, label):\n",
        "  classes_in_node = np.unique(train_data[label])\n",
        "  if len(classes_in_node) == 1:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmSk5xUd8SgM"
      },
      "outputs": [],
      "source": [
        "def leaf_class(train_data, label):\n",
        "    class_list, count_class = np.unique(train_data[label], return_counts=True)\n",
        "    idx = count_class.argmax()\n",
        "    return class_list[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkFc6PyRSTry"
      },
      "outputs": [],
      "source": [
        "def make_tree(train_data, label, class_list, n_thresholds, cur_depth, min_samples, max_depth):\n",
        "  if is_leaf(data, label) or cur_depth>=max_depth or len(train_data)<=min_samples:\n",
        "    return leaf_class(train_data, label)\n",
        "  else:\n",
        "    cur_depth += 1\n",
        "    split_feature, split_threshold = most_informative_feature(train_data, label, class_list, n_thresholds)\n",
        "    left_rows, right_rows = split(train_data[split_feature].values, split_threshold)\n",
        "    if len(left_rows)==0 or len(right_rows)==0:\n",
        "      return leaf_class(train_data, label)\n",
        "    else:\n",
        "      # build sub tree\n",
        "      split_condition = \"{} <= {}\".format(split_feature, split_threshold)\n",
        "      sub_tree = {split_condition : []}\n",
        "      # recursive call\n",
        "      left_branch = make_tree(train_data.iloc[left_rows], label, class_list, n_thresholds, cur_depth, min_samples, max_depth)\n",
        "      right_branch = make_tree(train_data.iloc[right_rows], label, class_list, n_thresholds, cur_depth, min_samples, max_depth)\n",
        "      if left_branch == right_branch:\n",
        "        sub_tree = left_branch\n",
        "      else:\n",
        "        # grow the tree\n",
        "        sub_tree[split_condition].append(left_branch)\n",
        "        sub_tree[split_condition].append(right_branch)\n",
        "      return sub_tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrEcz2r31Mek"
      },
      "outputs": [],
      "source": [
        "# id3 call\n",
        "def id3(train_data_m, label, n_thresholds=1, min_samples=4, max_depth=6):\n",
        "    train_data = train_data_m.copy()  # getting a copy of the dataset\n",
        "    class_list = train_data[label].unique()  # getting unqiue classes of the label\n",
        "    tree = make_tree(train_data, label, class_list, n_thresholds, 0, min_samples, max_depth)  # start calling recursion\n",
        "    return tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qYx-Fk6CAMF"
      },
      "outputs": [],
      "source": [
        "t = id3(train_data, 'Class')\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTgPotzITQL7"
      },
      "outputs": [],
      "source": [
        "def predict(test_point, tree):\n",
        "    if not isinstance(tree, dict):\n",
        "      return tree\n",
        "    question = list(tree.keys())[0]\n",
        "    attribute, value = question.split(\" <= \")\n",
        "    if test_point[attribute] <= float(value):\n",
        "        answer = tree[question][0]\n",
        "    else:\n",
        "        answer = tree[question][1]\n",
        "    return predict(test_point, answer)\n",
        "\n",
        "def evaluate(tree, test_data, label):\n",
        "    correct_preditct = 0\n",
        "    wrong_preditct = 0\n",
        "    for index in range(len(test_data.index)):  # for each row in the dataset\n",
        "        result = predict(test_data.iloc[index], tree)  # predict the row\n",
        "        if result == test_data[label].iloc[index]:  # predicted value and expected value is same or not\n",
        "            correct_preditct += 1  # increase correct count\n",
        "        else:\n",
        "            wrong_preditct += 1  # increase incorrect count\n",
        "    accuracy = correct_preditct / (correct_preditct + wrong_preditct)  # calculating accuracy\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL_3XYt33RH8"
      },
      "source": [
        "## Gaussian Naive Bayes \n",
        "Modufy the implemntation of naive Bayes to accout for numerical input features. The likelihood of each class ($p(data|class)$) is assumed to be a Gaussian $\\frac{1}{\\sqrt(\\sigma^2 2 \\pi)} \\exp (\\frac{1}{2} \\frac{(x-\\mu)}{\\sigma^2})$, where $\\mu, \\sigma^2$ are the mean and the variance for each class;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_QIqQgUn9X8"
      },
      "outputs": [],
      "source": [
        "def prior(train_data, label):\n",
        "  priors = train_data.groupby(by=label).apply(lambda x: len(x)/len(train_data))\n",
        "  return np.log(priors).values\n",
        "\n",
        "def mean_variance(train_data, label):\n",
        "  mean = train_data.groupby(by=label).apply(lambda x: x.mean(axis=0))\n",
        "  variance = train_data.groupby(by=label).apply(lambda x: x.var(axis=0))\n",
        "  return (mean.values, variance.values)\n",
        "\n",
        "def gaussian_density(mean, variance, point):\n",
        "  d = (1 / np.sqrt(2*np.pi*variance)) * np.exp((-(point - mean)**2) / (2*variance))\n",
        "  return d\n",
        "\n",
        "def train_gaussian_naive_bayes(train_data, label):\n",
        "  mean, variance = mean_variance(train_data, label)\n",
        "  priors = prior(train_data, label)\n",
        "  unique_labels = train_data[label].unique()\n",
        "  n_labels = len(unique_labels)\n",
        "  return {'n_labels': n_labels, 'unique_labels': unique_labels, 'n_classes': n_labels, 'mean': mean, \n",
        "          'variance': variance, 'prior': priors}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3sq6De4qIhM"
      },
      "outputs": [],
      "source": [
        "gaus_bayes = train_gaussian_naive_bayes(train_data, 'Class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK09w28tqO_l"
      },
      "outputs": [],
      "source": [
        "def posterior(point, mean, variance, class_list, n_classes, n_feat):\n",
        "  posteriors = []\n",
        "  for i in range(n_classes):\n",
        "    posterior = 0\n",
        "    for j in range(n_feat):\n",
        "      posterior += np.log(gaussian_density(mean[i][j], variance[i][j], point[j]))\n",
        "    posteriors.append(posterior)\n",
        "  return posteriors\n",
        "\n",
        "def predict(test_data, label, gaus_bayes):\n",
        "  predictions = []\n",
        "  n_feat = len(test_data.columns) - 1\n",
        "  for i in range(len(test_data)):\n",
        "    pr = gaus_bayes['prior']\n",
        "    post = posterior(test_data.iloc[i, :-1], gaus_bayes['mean'], gaus_bayes['variance'], \n",
        "                     gaus_bayes['unique_labels'], gaus_bayes['n_classes'], n_feat)\n",
        "    prob = pr + post\n",
        "    max_prob_class_idx = np.argmax(prob)\n",
        "    predictions.append(gaus_bayes['unique_labels'][max_prob_class_idx])\n",
        "  return predictions \n",
        "\n",
        "def evaluate(test_data, label, gaus_bayes):\n",
        "  gaus_pred = predict(test_data, label, gaus_bayes)\n",
        "  correct_predict = 0\n",
        "  wrong_predict = 0\n",
        "  for index in range(len(test_data.index)):  # for each row in the dataset\n",
        "        if gaus_pred[index] == test_data[label].iloc[index]:  # predicted value and expected value is same or not\n",
        "            correct_predict += 1  # increase correct count\n",
        "        else:\n",
        "            wrong_predict += 1  # increase incorrect count\n",
        "  accuracy = correct_predict / (correct_predict + wrong_predict)  # calculating accuracy\n",
        "  return accuracy"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
